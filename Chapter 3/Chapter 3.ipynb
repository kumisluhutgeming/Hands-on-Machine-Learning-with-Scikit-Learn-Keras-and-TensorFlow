{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds_s4pVw8rjK",
        "outputId": "a40d1179-dff5-49df-b869-5f05155d5759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BAB 3: KLASIFIKASI ---\n",
            "Semua library telah diimpor.\n",
            "\n",
            "[1. Mengunduh Data MNIST]\n",
            "Bentuk data (X): (70000, 784)\n",
            "Bentuk label (y): (70000,)\n",
            "Label untuk digit pertama: 5\n",
            "\n",
            "[2. Memisahkan Data Latih dan Tes]\n",
            "Data latih dan tes telah dipisah.\n",
            "\n",
            "[3. Melatih Klasifikasi Biner (Detektor Angka 5)]\n",
            "Prediksi SGD untuk 5 (angka 5): [ True]\n",
            "\n",
            "[4. Mengukur Kinerja Model]\n",
            "Menghitung akurasi (bisa menipu)...\n",
            "Menghitung Confusion Matrix...\n",
            "Confusion Matrix (Detektor '5'):\n",
            " [[53892   687]\n",
            " [ 1891  3530]]\n",
            "Menghitung Precision, Recall, F1-Score...\n",
            "Precision: 0.8371\n",
            "Recall: 0.6512\n",
            "F1 Score: 0.7325\n",
            "Menganalisis Precision/Recall Trade-off...\n",
            "Menghitung Kurva ROC...\n",
            "ROC AUC Score (SGD): 0.9605\n",
            "Melatih RandomForestClassifier untuk perbandingan...\n",
            "ROC AUC Score (Random Forest): 0.9983\n",
            "\n",
            "[5. Klasifikasi Multikelas (0-9)]\n",
            "Prediksi SVM untuk 5 (angka 5): [5]\n",
            "Prediksi SGD untuk 5 (angka 5): [3]\n",
            "Melakukan scaling data untuk SGD...\n",
            "\n",
            "[6. Analisis Error]\n"
          ]
        }
      ],
      "source": [
        "# MENGIMPOR SEMUA LIBRARY YANG DIPERLUKAN UNTUK BAB 3\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Mengatur default plotting\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Untuk plot di dalam notebook (jika Anda menggunakan Jupyter)\n",
        "# %matplotlib inline\n",
        "\n",
        "print(\"--- BAB 3: KLASIFIKASI ---\")\n",
        "print(\"Semua library telah diimpor.\")\n",
        "\n",
        "# 1. MENGUNDUH DATASET MNIST\n",
        "print(\"\\n[1. Mengunduh Data MNIST]\")\n",
        "# Catatan: fetch_openml() mengunduh dataset dari openml.org.\n",
        "# 'as_frame=False' memastikan kita mendapatkan array NumPy, bukan DataFrame pandas.\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
        "# print(mnist.keys()) # Melihat struktur dataset\n",
        "\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "\n",
        "# Mengubah label y (string) menjadi integer (uint8)\n",
        "y = y.astype(np.uint8)\n",
        "\n",
        "print(f\"Bentuk data (X): {X.shape}\") # (70000 instance, 784 fitur)\n",
        "print(f\"Bentuk label (y): {y.shape}\") # (70000 label)\n",
        "\n",
        "# Menampilkan satu digit (instance pertama)\n",
        "some_digit = X[0]\n",
        "some_digit_image = some_digit.reshape(28, 28)\n",
        "\n",
        "# plt.imshow(some_digit_image, cmap=\"binary\")\n",
        "# plt.axis(\"off\")\n",
        "# plt.show()\n",
        "print(f\"Label untuk digit pertama: {y[0]}\") # Seharusnya angka 5\n",
        "\n",
        "# 2. MEMBAGI DATA LATIH DAN TES\n",
        "print(\"\\n[2. Memisahkan Data Latih dan Tes]\")\n",
        "# Dataset MNIST sudah diurutkan dan dibagi (60k latih, 10k tes)\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
        "print(\"Data latih dan tes telah dipisah.\")\n",
        "\n",
        "# 3. MELATIH KLASIFIKASI BINER (BINARY CLASSIFIER)\n",
        "print(\"\\n[3. Melatih Klasifikasi Biner (Detektor Angka 5)]\")\n",
        "# Kita sederhanakan masalah: \"apakah ini 5\" (True) atau \"bukan 5\" (False)\n",
        "\n",
        "y_train_5 = (y_train == 5)\n",
        "y_test_5 = (y_test == 5)\n",
        "\n",
        "# Menggunakan Stochastic Gradient Descent (SGD) Classifier\n",
        "# SGD efisien untuk data besar\n",
        "sgd_clf = SGDClassifier(random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_5)\n",
        "\n",
        "print(f\"Prediksi SGD untuk {y[0]} (angka 5): {sgd_clf.predict([some_digit])}\")\n",
        "\n",
        "# 4. MENGUKUR KINERJA\n",
        "print(\"\\n[4. Mengukur Kinerja Model]\")\n",
        "\n",
        "# 4a. Mengukur Akurasi Menggunakan Cross-Validation\n",
        "print(\"Menghitung akurasi (bisa menipu)...\")\n",
        "# cv=3 berarti K-fold cross-validation dengan 3 fold\n",
        "# score_accuracy = cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
        "# print(f\"Akurasi Cross-Val (3-fold): {score_accuracy}\")\n",
        "\n",
        "# 4b. Classifier \"Bodoh\" sebagai Baseline\n",
        "# Mari kita buat classifier yang selalu menebak \"bukan 5\"\n",
        "class Never5Classifier(BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def predict(self, X):\n",
        "        return np.zeros((len(X), 1), dtype=bool)\n",
        "\n",
        "never_5_clf = Never5Classifier()\n",
        "# score_never5 = cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
        "# print(f\"Akurasi 'Never 5' Classifier: {score_never5}\")\n",
        "# Hasilnya > 90%! Ini membuktikan akurasi adalah metrik berbahaya pada skewed dataset.\n",
        "\n",
        "# 4c. Confusion Matrix\n",
        "print(\"Menghitung Confusion Matrix...\")\n",
        "# cross_val_predict melakukan K-fold cross-validation, tapi mengembalikan prediksi\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
        "\n",
        "cm = confusion_matrix(y_train_5, y_train_pred)\n",
        "print(\"Confusion Matrix (Detektor '5'):\\n\", cm)\n",
        "# Baris: Kelas Aktual (Bukan 5, Adalah 5)\n",
        "# Kolom: Kelas Prediksi (Bukan 5, Adalah 5)\n",
        "# [[TN, FP],\n",
        "#  [FN, TP]]\n",
        "# TN (True Negative): 53892 (benar menebak bukan 5)\n",
        "# FP (False Positive): 687 (salah menebak 5, padahal bukan)\n",
        "# FN (False Negative): 1891 (salah menebak bukan 5, padahal 5)\n",
        "# TP (True Positive): 3530 (benar menebak 5)\n",
        "\n",
        "# 4d. Precision, Recall, dan F1-Score\n",
        "print(\"Menghitung Precision, Recall, F1-Score...\")\n",
        "# Precision = TP / (TP + FP) -> Seberapa akurat tebakan '5' kita?\n",
        "# Recall = TP / (TP + FN) -> Berapa banyak '5' yang berhasil kita temukan?\n",
        "print(f\"Precision: {precision_score(y_train_5, y_train_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_train_5, y_train_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_train_5, y_train_pred):.4f}\")\n",
        "\n",
        "# 4e. Precision/Recall Trade-off\n",
        "print(\"Menganalisis Precision/Recall Trade-off...\")\n",
        "# SGDClassifier membuat keputusan berdasarkan skor\n",
        "# Kita bisa mendapatkan skor ini alih-alih prediksi\n",
        "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
        "                             method=\"decision_function\")\n",
        "\n",
        "# Menghitung P dan R untuk semua kemungkinan threshold\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
        "\n",
        "# Fungsi untuk plot P/R vs Threshold\n",
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
        "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
        "    plt.legend(loc=\"center right\", fontsize=16)\n",
        "    plt.xlabel(\"Threshold\", fontsize=16)\n",
        "    plt.grid(True)\n",
        "    plt.axis([-50000, 50000, 0, 1])\n",
        "\n",
        "# Panggil fungsi plot (di-comment agar tidak auto-tampil)\n",
        "# print(\"Plotting Precision/Recall vs Threshold...\")\n",
        "# plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
        "# plt.show()\n",
        "\n",
        "# Contoh: Mencari threshold untuk 90% precision\n",
        "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
        "# y_train_pred_90 = (y_scores >= threshold_90_precision)\n",
        "# print(f\"Precision pada threshold 90%: {precision_score(y_train_5, y_train_pred_90)}\")\n",
        "# print(f\"Recall pada threshold 90%: {recall_score(y_train_5, y_train_pred_90)}\")\n",
        "\n",
        "# 4f. Kurva ROC (Receiver Operating Characteristic)\n",
        "print(\"Menghitung Kurva ROC...\")\n",
        "# Memplot True Positive Rate (Recall) vs False Positive Rate (FPR)\n",
        "# FPR = FP / (FP + TN) -> Proporsi 'bukan 5' yang salah dikira '5'\n",
        "fpr, tpr, thresholds_roc = roc_curve(y_train_5, y_scores)\n",
        "\n",
        "# Fungsi untuk plot Kurva ROC\n",
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'k--') # Garis acak (diagonal)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
        "    plt.grid(True)\n",
        "\n",
        "# Panggil fungsi plot (di-comment)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plot_roc_curve(fpr, tpr)\n",
        "# plt.show()\n",
        "\n",
        "# Area Under the Curve (AUC)\n",
        "print(f\"ROC AUC Score (SGD): {roc_auc_score(y_train_5, y_scores):.4f}\")\n",
        "\n",
        "# 4g. Membandingkan dengan RandomForestClassifier\n",
        "print(\"Melatih RandomForestClassifier untuk perbandingan...\")\n",
        "forest_clf = RandomForestClassifier(random_state=42)\n",
        "# RandomForest tidak punya decision_function(), tapi punya predict_proba()\n",
        "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
        "                                    method=\"predict_proba\")\n",
        "\n",
        "# Kita gunakan probabilitas kelas positif sebagai skor\n",
        "y_scores_forest = y_probas_forest[:, 1]\n",
        "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)\n",
        "\n",
        "# Plot perbandingan ROC\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plot_roc_curve(fpr, tpr, \"SGD\")\n",
        "# plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
        "# plt.legend(loc=\"lower right\", fontsize=16)\n",
        "# plt.show()\n",
        "\n",
        "print(f\"ROC AUC Score (Random Forest): {roc_auc_score(y_train_5, y_scores_forest):.4f}\")\n",
        "# Random Forest jauh lebih baik\n",
        "\n",
        "# 5. KLASIFIKASI MULTIKELAS\n",
        "print(\"\\n[5. Klasifikasi Multikelas (0-9)]\")\n",
        "\n",
        "# Melatih SVM (Support Vector Machine)\n",
        "# Scikit-Learn SVC otomatis menggunakan strategi One-vs-One (OvO)\n",
        "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
        "# Kita latih pada SEMUA label (y_train), bukan y_train_5\n",
        "# Kita latih pada subset kecil (2000) agar cepat\n",
        "svm_clf.fit(X_train[:2000], y_train[:2000])\n",
        "print(f\"Prediksi SVM untuk {y[0]} (angka 5): {svm_clf.predict([some_digit])}\")\n",
        "\n",
        "# SGDClassifier bisa menangani multikelas secara langsung (OvR defaultnya)\n",
        "sgd_clf.fit(X_train, y_train) # Latih pada semua data dan semua kelas\n",
        "print(f\"Prediksi SGD untuk {y[0]} (angka 5): {sgd_clf.predict([some_digit])}\")\n",
        "# sgd_clf.decision_function([some_digit]) # Akan memberikan 10 skor\n",
        "\n",
        "# Evaluasi classifier multikelas\n",
        "# print(\"Akurasi SGD (multikelas, non-scaled):\")\n",
        "# print(cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\"))\n",
        "\n",
        "# Scaling SANGAT PENTING untuk performa\n",
        "print(\"Melakukan scaling data untuk SGD...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
        "# print(\"Akurasi SGD (multikelas, scaled):\")\n",
        "# print(cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\"))\n",
        "\n",
        "# 6. ANALISIS ERROR\n",
        "print(\"\\n[6. Analisis Error]\")\n",
        "# Kita gunakan model SGD yang sudah di-scaling\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
        "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
        "\n",
        "print(\"Plotting Confusion Matrix (multikelas)...\")\n",
        "# plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
        "# plt.show()\n",
        "\n",
        "# Fokus pada error saja dengan normalisasi\n",
        "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
        "norm_conf_mx = conf_mx / row_sums\n",
        "np.fill_diagonal(norm_conf_mx, 0) # Ubah diagonal (prediksi benar) menjadi 0\n",
        "\n",
        "# print(\"Plotting Matriks Error (ternormalisasi)...\")\n",
        "# plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
        "# plt.show()\n",
        "# Penjelasan: Baris = Aktual, Kolom = Prediksi.\n",
        "# Kolom 8 yang terang berarti banyak angka LAIN (baris) salah diprediksi sebagai 8.\n",
        "# Baris 3 dan 5 yang terang berarti angka 3 dan 5 sering tertukar.\n",
        "\n",
        "# 7. KLASIFIKASI MULTILABEL\n",
        "print(\"\\n[7. Klasifikasi Multilabel]\")\n",
        "# Sebuah instance bisa memiliki beberapa label\n",
        "\n",
        "# Contoh: Label 1: Apakah angkanya besar (>= 7)?\n",
        "y_train_large = (y_train >= 7)\n",
        "# Contoh: Label 2: Apakah angkanya ganjil?\n",
        "y_train_odd = (y_train % 2 == 1)\n",
        "# Menggabungkan kedua label\n",
        "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf.fit(X_train, y_multilabel)\n",
        "\n",
        "print(f\"Prediksi Multilabel untuk {y[0]} (angka 5): {knn_clf.predict([some_digit])}\")\n",
        "# Output: [[False, True]] (angka 5 TIDAK besar, tapi GANJIL)\n",
        "\n",
        "# Evaluasi Multilabel (contoh: F1 score rata-rata)\n",
        "# y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
        "# f1_macro = f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")\n",
        "# print(f\"F1 Score (macro) Multilabel: {f1_macro:.4f}\")\n",
        "\n",
        "# 8. KLASIFIKASI MULTIOUTPUT\n",
        "print(\"\\n[8. Klasifikasi Multioutput (Contoh: Denoising)]\")\n",
        "# Generalisasi dari multilabel; setiap label bisa multiclass.\n",
        "# Contoh: Menghilangkan noise (setiap pixel adalah label)\n",
        "\n",
        "# Membuat data latih yang noisy (menambah noise acak)\n",
        "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
        "X_train_mod = X_train + noise\n",
        "\n",
        "# Membuat data tes yang noisy\n",
        "noise_test = np.random.randint(0, 100, (len(X_test), 784))\n",
        "X_test_mod = X_test + noise_test\n",
        "\n",
        "# Targetnya adalah gambar bersih (y adalah X)\n",
        "y_train_mod = X_train\n",
        "y_test_mod = X_test\n",
        "\n",
        "# Latih model untuk memetakan gambar noisy ke gambar bersih\n",
        "knn_clf.fit(X_train_mod, y_train_mod)\n",
        "\n",
        "# Coba bersihkan satu digit\n",
        "some_index = 0\n",
        "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
        "\n",
        "# Fungsi helper untuk plot\n",
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap=mpl.cm.binary, interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "# Plot perbandingan (di-comment)\n",
        "# plt.figure(figsize=(8, 4))\n",
        "# plt.subplot(121); plot_digit(X_test_mod[some_index])\n",
        "# plt.title(\"Noisy Input\")\n",
        "# plt.subplot(122); plot_digit(clean_digit)\n",
        "# plt.title(\"Denoised Output\")\n",
        "# plt.show()\n",
        "\n",
        "print(\"\\n--- Selesai Bab 3 ---\")"
      ]
    }
  ]
}