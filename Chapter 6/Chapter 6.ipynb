{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a778cVvmAk-r",
        "outputId": "ee60f0ac-ba6b-4224-d56b-3401cfcadecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BAB 6: DECISION TREES (POHON KEPUTUSAN) ---\n",
            "Semua library telah diimpor.\n",
            "\n",
            "[1. Melatih dan Memvisualisasikan (Klasifikasi)]\n",
            "DecisionTreeClassifier (max_depth=2) telah dilatih pada data Iris.\n",
            "Mengekspor visualisasi pohon ke 'iris_tree.dot'...\n",
            "File 'iris_tree.dot' telah disimpan di ./images/decision_trees\n",
            "  Untuk melihat, jalankan di terminal Anda:\n",
            "  dot -Tpng ./images/decision_trees/iris_tree.dot -o ./images/decision_trees/iris_tree.png\n",
            "\n",
            "[2. Membuat Prediksi dan Estimasi Probabilitas]\n",
            "Prediksi untuk [petal length=5, petal width=1.5]:\n",
            "  Kelas (prediksi): [1]\n",
            "  Probabilitas kelas: [[0.         0.90740741 0.09259259]]\n",
            "\n",
            "[3. Regularisasi Hyperparameters]\n",
            "Telah melatih 2 model (overfit vs regularisasi) pada dataset moons.\n",
            "\n",
            "[4. Regresi dengan Decision Trees]\n",
            "DecisionTreeRegressor (max_depth=2 dan 3) telah dilatih.\n",
            "\n",
            "[5. Kelemahan: Ketidakstabilan]\n",
            "Melatih 2 pohon: 1 pada data asli, 1 pada data yang dirotasi 45 derajat.\n",
            "\n",
            "--- Selesai Bab 6 ---\n"
          ]
        }
      ],
      "source": [
        "# MENGIMPOR SEMUA LIBRARY YANG DIPERLUKAN UNTUK BAB 6\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Impor untuk Decision Trees\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import export_graphviz # Untuk visualisasi\n",
        "\n",
        "# Impor untuk data non-linear dan perbandingan\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "# Mengatur default plotting\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Mengatur path untuk menyimpan gambar\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"decision_trees\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "print(\"--- BAB 6: DECISION TREES (POHON KEPUTUSAN) ---\")\n",
        "print(\"Semua library telah diimpor.\")\n",
        "\n",
        "# 1. MELATIH DAN MEMVISUALISASIKAN DECISION TREE (KLASIFIKASI)\n",
        "print(\"\\n[1. Melatih dan Memvisualisasikan (Klasifikasi)]\")\n",
        "\n",
        "# Teori: Decision Trees adalah model 'white box' yang intuitif.\n",
        "# Mereka adalah serangkaian pertanyaan \"jika-maka\" yang dipelajari dari data.\n",
        "\n",
        "# Menggunakan dataset Iris\n",
        "iris = load_iris()\n",
        "X_iris = iris.data[:, 2:] # Fitur: petal length (cm) dan petal width (cm)\n",
        "y_iris = iris.target\n",
        "\n",
        "# Melatih DecisionTreeClassifier\n",
        "# Kita batasi kedalaman pohon (max_depth=2) untuk mencegah overfitting\n",
        "# dan agar mudah divisualisasikan. Ini adalah bentuk REGULARISASI.\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "tree_clf.fit(X_iris, y_iris)\n",
        "\n",
        "print(\"DecisionTreeClassifier (max_depth=2) telah dilatih pada data Iris.\")\n",
        "\n",
        "# Memvisualisasikan pohon yang sudah dilatih\n",
        "# Ini menghasilkan file .dot yang bisa dikonversi ke PNG/PDF\n",
        "# menggunakan alat 'dot' dari Graphviz.\n",
        "# (Anda harus menginstal Graphviz secara terpisah di sistem Anda untuk menjalankan 'dot')\n",
        "print(\"Mengekspor visualisasi pohon ke 'iris_tree.dot'...\")\n",
        "export_graphviz(\n",
        "        tree_clf,\n",
        "        out_file=os.path.join(IMAGES_PATH, \"iris_tree.dot\"),\n",
        "        feature_names=iris.feature_names[2:],\n",
        "        class_names=iris.target_names,\n",
        "        rounded=True,\n",
        "        filled=True\n",
        "    )\n",
        "\n",
        "print(f\"File 'iris_tree.dot' telah disimpan di {IMAGES_PATH}\")\n",
        "print(\"  Untuk melihat, jalankan di terminal Anda:\")\n",
        "print(f\"  dot -Tpng {IMAGES_PATH}/iris_tree.dot -o {IMAGES_PATH}/iris_tree.png\")\n",
        "\n",
        "\n",
        "# 2. MEMBUAT PREDIKSI DAN ESTIMASI PROBABILITAS\n",
        "print(\"\\n[2. Membuat Prediksi dan Estimasi Probabilitas]\")\n",
        "# Teori: Prediksi dibuat dengan 'menelusuri' pohon dari root (akar)\n",
        "# hingga ke leaf node (daun) berdasarkan fitur instance.\n",
        "\n",
        "# Penjelasan file .dot:\n",
        "# - samples: Berapa banyak instance latih yang masuk ke node ini.\n",
        "# - value: [jml kelas 0, jml kelas 1, jml kelas 2] di node ini.\n",
        "# - gini: Gini Impurity (ukuran kemurnian). 0 = murni (semua instance 1 kelas).\n",
        "# - class: Kelas yang diprediksi di node ini (berdasarkan 'value' mayoritas).\n",
        "\n",
        "# Contoh prediksi: petal length=5cm, petal width=1.5cm\n",
        "# 1. (Root): petal length <= 2.45? (5 <= 2.45 adalah False) -> Pergi ke node Kanan.\n",
        "# 2. (Depth 1, Kanan): petal width <= 1.75? (1.5 <= 1.75 adalah True) -> Pergi ke node Kiri.\n",
        "# 3. (Depth 2, Kiri): Ini adalah leaf node. Prediksi = 'versicolor' (value=[0, 49, 5])\n",
        "\n",
        "print(f\"Prediksi untuk [petal length=5, petal width=1.5]:\")\n",
        "print(f\"  Kelas (prediksi): {tree_clf.predict([[5, 1.5]])}\") # Output: [1] (versicolor)\n",
        "\n",
        "# Teori: Probabilitas adalah rasio instance kelas di leaf node tempat instance tersebut jatuh.\n",
        "# Node [0, 49, 5] memiliki total 54 sampel.\n",
        "# P(setosa) = 0/54 = 0%\n",
        "# P(versicolor) = 49/54 = ~90.7%\n",
        "# P(virginica) = 5/54 = ~9.3%\n",
        "print(f\"  Probabilitas kelas: {tree_clf.predict_proba([[5, 1.5]])}\")\n",
        "\n",
        "\n",
        "# 3. REGULARISASI HYPERPARAMETERS\n",
        "print(\"\\n[3. Regularisasi Hyperparameters]\")\n",
        "# Teori: Jika tidak dibatasi, Decision Trees akan terus membelah\n",
        "# sampai setiap daun murni. Ini menyebabkan OVERFITTING parah.\n",
        "# Kita menggunakan hyperparameter untuk membatasinya (meregularisasi).\n",
        "\n",
        "# Hyperparameter regularisasi utama:\n",
        "# - max_depth: Kedalaman maksimum pohon.\n",
        "# - min_samples_split: Jml minimum instance agar node bisa dipecah.\n",
        "# - min_samples_leaf: Jml minimum instance yang harus ada di leaf node.\n",
        "# - max_features: Jml maksimum fitur yang dievaluasi untuk split.\n",
        "# Mengubah hyperparameter ini (menaikkan min_*, menurunkan max_*)\n",
        "# akan meningkatkan regularisasi dan mengurangi overfitting.\n",
        "\n",
        "# Contoh: Melatih pada dataset moons (non-linear)\n",
        "Xm, ym = make_moons(n_samples=100, noise=0.25, random_state=53)\n",
        "\n",
        "# Model 1: Tanpa regularisasi (default)\n",
        "tree_clf1 = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf1.fit(Xm, ym)\n",
        "\n",
        "# Model 2: Dengan regularisasi (min_samples_leaf=4)\n",
        "tree_clf2 = DecisionTreeClassifier(min_samples_leaf=4, random_state=42)\n",
        "tree_clf2.fit(Xm, ym)\n",
        "\n",
        "print(\"Telah melatih 2 model (overfit vs regularisasi) pada dataset moons.\")\n",
        "\n",
        "# Plot decision boundaries (di-comment agar tidak auto-tampil)\n",
        "# plt.figure(figsize=(11, 4))\n",
        "# plt.subplot(121)\n",
        "# DecisionBoundaryDisplay.from_estimator(tree_clf1, Xm, alpha=0.4, response_method=\"predict\")\n",
        "# plt.plot(Xm[:, 0][ym==0], Xm[:, 1][ym==0], \"bs\")\n",
        "# plt.plot(Xm[:, 0][ym==1], Xm[:, 1][ym==1], \"g^\")\n",
        "# plt.title(\"Tanpa Regularisasi (Overfitting)\")\n",
        "# plt.subplot(122)\n",
        "# DecisionBoundaryDisplay.from_estimator(tree_clf2, Xm, alpha=0.4, response_method=\"predict\")\n",
        "# plt.plot(Xm[:, 0][ym==0], Xm[:, 1][ym==0], \"bs\")\n",
        "# plt.plot(Xm[:, 0][ym==1], Xm[:, 1][ym==1], \"g^\")\n",
        "# plt.title(\"Dengan Regularisasi (min_samples_leaf=4)\")\n",
        "# plt.show()\n",
        "# Model 2 (kanan) terlihat memiliki generalisasi yang lebih baik.\n",
        "\n",
        "# 4. REGRESI DENGAN DECISION TREES\n",
        "print(\"\\n[4. Regresi dengan Decision Trees]\")\n",
        "# Teori: Pohon juga bisa dipakai untuk regresi.\n",
        "# Perbedaannya adalah:\n",
        "# 1. Kriteria split: Alih-alih meminimalkan Gini/Entropy (impurity),\n",
        "#    algoritma CART meminimalkan MSE (Mean Squared Error).\n",
        "# 2. Prediksi: Alih-alih memprediksi 'kelas' di leaf node, pohon\n",
        "#    memprediksi 'nilai' (yaitu nilai rata-rata dari semua instance di leaf tsb).\n",
        "\n",
        "# Membuat data regresi kuadratik palsu\n",
        "np.random.seed(42)\n",
        "m_reg = 200\n",
        "X_reg = np.random.rand(m_reg, 1)\n",
        "y_reg = 4 * (X_reg - 0.5) ** 2 + np.random.randn(m_reg, 1) / 10 # y = 4(x-0.5)^2 + noise\n",
        "\n",
        "# Melatih DecisionTreeRegressor\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg1.fit(X_reg, y_reg)\n",
        "\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
        "tree_reg2.fit(X_reg, y_reg)\n",
        "\n",
        "print(\"DecisionTreeRegressor (max_depth=2 dan 3) telah dilatih.\")\n",
        "\n",
        "# Visualisasi hasil regresi (di-comment)\n",
        "# X_new_reg = np.linspace(0, 1, 500).reshape(-1, 1)\n",
        "# y_pred_reg1 = tree_reg1.predict(X_new_reg)\n",
        "# y_pred_reg2 = tree_reg2.predict(X_new_reg)\n",
        "#\n",
        "# plt.figure(figsize=(11, 4))\n",
        "# plt.subplot(121)\n",
        "# plt.plot(X_reg, y_reg, \"b.\")\n",
        "# plt.plot(X_new_reg, y_pred_reg1, \"r-\", linewidth=2, label=r\"$\\hat{y}$ (max_depth=2)\")\n",
        "# plt.axis([0, 1, -0.2, 1.1])\n",
        "# plt.xlabel(\"$x_1$\")\n",
        "# plt.ylabel(\"$y$\")\n",
        "# plt.legend()\n",
        "#\n",
        "# plt.subplot(122)\n",
        "# plt.plot(X_reg, y_reg, \"b.\")\n",
        "# plt.plot(X_new_reg, y_pred_reg2, \"r-\", linewidth=2, label=r\"$\\hat{y}$ (max_depth=3)\")\n",
        "# plt.axis([0, 1, -0.2, 1.1])\n",
        "# plt.xlabel(\"$x_1$\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "# Plot menunjukkan bahwa prediksi adalah nilai rata-rata konstan di dalam setiap leaf.\n",
        "# Model regresi pohon (tanpa regularisasi) juga akan overfit.\n",
        "# tree_reg_overfit = DecisionTreeRegressor(random_state=42)\n",
        "# tree_reg_overfit.fit(X_reg, y_reg) # Akan sangat overfit\n",
        "\n",
        "# 5. KETIDAKSTABILAN DECISION TREES\n",
        "print(\"\\n[5. Kelemahan: Ketidakstabilan]\")\n",
        "# Teori: Kelemahan utama Decision Trees adalah mereka SANGAT sensitif\n",
        "# terhadap variasi kecil pada data latih dan rotasi data.\n",
        "\n",
        "# Contoh sensitivitas terhadap rotasi data\n",
        "np.random.seed(6)\n",
        "Xs = np.random.rand(100, 2) - 0.5\n",
        "ys = (Xs[:, 0] > 0).astype(np.float32) * 2\n",
        "\n",
        "angle = np.pi / 4  # Rotasi 45 derajat\n",
        "rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
        "Xsr = Xs.dot(rotation_matrix)\n",
        "\n",
        "# Latih pohon pada data asli dan data yang dirotasi\n",
        "tree_clf_s = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf_s.fit(Xs, ys)\n",
        "tree_clf_sr = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf_sr.fit(Xsr, ys)\n",
        "\n",
        "print(\"Melatih 2 pohon: 1 pada data asli, 1 pada data yang dirotasi 45 derajat.\")\n",
        "\n",
        "# Plot perbandingan (di-comment)\n",
        "# plt.figure(figsize=(11, 4))\n",
        "# plt.subplot(121)\n",
        "# DecisionBoundaryDisplay.from_estimator(tree_clf_s, Xs, alpha=0.4, response_method=\"predict\")\n",
        "# plt.plot(Xs[:, 0][ys==0], Xs[:, 1][ys==0], \"bs\")\n",
        "# plt.plot(Xs[:, 0][ys==1], Xs[:, 1][ys==1], \"g^\")\n",
        "# plt.title(\"Data Asli (Batas Ortogonal)\")\n",
        "#\n",
        "# plt.subplot(122)\n",
        "# DecisionBoundaryDisplay.from_estimator(tree_clf_sr, Xsr, alpha=0.4, response_method=\"predict\")\n",
        "# plt.plot(Xsr[:, 0][ys==0], Xsr[:, 1][ys==0], \"bs\")\n",
        "# plt.plot(Xsr[:, 0][ys==1], Xsr[:, 1][ys==1], \"g^\")\n",
        "# plt.title(\"Data yang Dirotasi 45Â° (Batas Rumit)\")\n",
        "# plt.show()\n",
        "\n",
        "# Hasil: Pohon di data asli (kiri) punya batas keputusan sederhana.\n",
        "# Pohon di data yang dirotasi (kanan) punya batas keputusan yang\n",
        "# sangat rumit dan tidak perlu (overfitting).\n",
        "# Ini adalah kelemahan utama. Random Forest (Bab 7) akan memperbaiki ini.\n",
        "\n",
        "print(\"\\n--- Selesai Bab 6 ---\")"
      ]
    }
  ]
}